{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 필요 모듈 및 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from konlpy.tag import Kkma\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42803, 5)\n",
      "(9987, 3)\n",
      "(9987, 2)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('데이터/train_v2.csv')\n",
    "test = pd.read_csv('데이터/test_v2.csv')\n",
    "submission = pd.read_csv('데이터/extractive_sample_submission_v2.csv')\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(submission.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 클래스 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 텍스트 전처리 및 토크나이징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.kkma = Kkma()\n",
    "        self.okt = Okt()\n",
    "        self.stopwords = ['중인' ,'만큼', '마찬가지', '꼬집었', \"연합뉴스\", \"데일리\",\n",
    "                          \"동아일보\", \"중앙일보\", \"조선일보\", \"기자\", \"아\", \"휴\", \"아이구\",\n",
    "                          \"아이쿠\", \"아이고\", \"어\", \"나\", \"우리\", \"저희\", \"따라\", \"의해\",\n",
    "                          \"을\", \"를\", \"에\", \"의\", \"가\"]\n",
    "\n",
    "        \n",
    "    def text2sentences(self, text):\n",
    "        sentences = text[2:-2].split(\"', '\")\n",
    "        return sentences\n",
    "    \n",
    "\n",
    "    def get_nouns(self, sentences):\n",
    "        nouns = []\n",
    "        for sentence in sentences:\n",
    "            if sentence is not '':\n",
    "                nouns.append(' '.join([noun for noun in self.okt.nouns(str(sentence))\n",
    "            if noun not in self.stopwords and len(noun) > 1]))\n",
    "        return nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 tf-idf 모델 적용 및 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphMatrix(object):\n",
    "    def __init__(self):\n",
    "        self.tfidf = TfidfVectorizer()\n",
    "        self.cnt_vec = CountVectorizer()\n",
    "        self.graph_sentence = []\n",
    "\n",
    "    def build_sent_graph(self, sentence):\n",
    "        tfidf_mat = self.tfidf.fit_transform(sentence).toarray()\n",
    "        self.graph_sentence = np.dot(tfidf_mat, tfidf_mat.T)\n",
    "        return self.graph_sentence\n",
    "\n",
    "    def build_words_graph(self, sentence):\n",
    "        cnt_vec_mat = normalize(self.cnt_vec.fit_transform(sentence).toarray().astype(float), axis=0)\n",
    "        vocab = self.cnt_vec.vocabulary_\n",
    "        return np.dot(cnt_vec_mat.T, cnt_vec_mat), {vocab[word] : word for word in vocab}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 텍스트 랭크 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rank(object):\n",
    "    def get_ranks(self, graph, d=0.85): # d = damping factor\n",
    "        A = graph\n",
    "        matrix_size = A.shape[0]\n",
    "        for id in range(matrix_size):\n",
    "            A[id, id] = 0 # diagonal 부분을 0으로\n",
    "            link_sum = np.sum(A[:,id]) # A[:, id] = A[:][id]\n",
    "            if link_sum != 0:\n",
    "                A[:, id] /= link_sum\n",
    "            A[:, id] *= -d\n",
    "            A[id, id] = 1\n",
    "\n",
    "        B = (1-d) * np.ones((matrix_size, 1))\n",
    "        ranks = np.linalg.solve(A, B) # 연립방정식 Ax = b\n",
    "        return {idx: r[0] for idx, r in enumerate(ranks)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 텍스트랭크 적용 및 추출요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRank(object):\n",
    "    def __init__(self, text):\n",
    "        self.sent_tokenize = SentenceTokenizer()\n",
    "        if text[:5] in ('http:', 'https'):\n",
    "            self.sentences = self.sent_tokenize.url2sentences(text)\n",
    "        else:\n",
    "            self.sentences = self.sent_tokenize.text2sentences(text)\n",
    "\n",
    "        self.nouns = self.sent_tokenize.get_nouns(self.sentences)\n",
    "\n",
    "        self.graph_matrix = GraphMatrix()\n",
    "        self.sent_graph = self.graph_matrix.build_sent_graph(self.nouns)\n",
    "        self.words_graph, self.idx2word = self.graph_matrix.build_words_graph(self.nouns)\n",
    "\n",
    "        self.rank = Rank()\n",
    "        self.sent_rank_idx = self.rank.get_ranks(self.sent_graph)\n",
    "        self.sorted_sent_rank_idx = sorted(self.sent_rank_idx, key=lambda k: self.sent_rank_idx[k], reverse=True)\n",
    "\n",
    "        self.word_rank_idx = self.rank.get_ranks(self.words_graph)\n",
    "        self.sorted_word_rank_idx = sorted(self.word_rank_idx, key=lambda k: self.word_rank_idx[k], reverse=True)\n",
    "\n",
    "    def summarize_index(self, sent_num=3):\n",
    "        summary = []\n",
    "        index=[]\n",
    "        for idx in self.sorted_sent_rank_idx[:sent_num]:\n",
    "            index.append(idx)\n",
    "  \n",
    "        index.sort()\n",
    "        for idx in index:\n",
    "            summary.append(idx)\n",
    "        return summary\n",
    "    \n",
    "    def summarize_sentence(self, sent_num=3):\n",
    "        summary = []\n",
    "        index=[]\n",
    "        for idx in self.sorted_sent_rank_idx[:sent_num]:\n",
    "            index.append(idx)\n",
    "  \n",
    "        index.sort()\n",
    "        for idx in index:\n",
    "            summary.append(self.sentences[idx])\n",
    "        return summary\n",
    "\n",
    "    def keywords(self, word_num=10):\n",
    "        rank = Rank()\n",
    "        rank_idx = rank.get_ranks(self.words_graph)\n",
    "        sorted_rank_idx = sorted(rank_idx, key=lambda k: rank_idx[k], reverse=True)\n",
    "\n",
    "        keywords = []\n",
    "        index=[]\n",
    "        for idx in sorted_rank_idx[:word_num]:\n",
    "            index.append(idx)\n",
    "\n",
    "        #index.sort()\n",
    "        for idx in index:\n",
    "            keywords.append(self.idx2word[idx])\n",
    "\n",
    "        return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-69-e088ac81ff3e>\u001b[0m in \u001b[0;36mresult\u001b[1;34m(dfm)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdfm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mtextrank\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextRank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mtextrank_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtextrank\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummarize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mtextrank_index_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtextrank_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-54-31607e39a424>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext2sentences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnouns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_nouns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGraphMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-84548eba2488>\u001b[0m in \u001b[0;36mget_nouns\u001b[1;34m(self, sentences)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m                 nouns.append(' '.join([noun for noun in self.okt.nouns(str(sentence))\n\u001b[0m\u001b[0;32m     21\u001b[0m             if noun not in self.stopwords and len(noun) > 1]))\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnouns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py\u001b[0m in \u001b[0;36mnouns\u001b[1;34m(self, phrase)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;34m\"\"\"Noun extractor.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[0mtagged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtagged\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Noun'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py\u001b[0m in \u001b[0;36mpos\u001b[1;34m(self, phrase, norm, stem, join)\u001b[0m\n\u001b[0;32m     61\u001b[0m                     \u001b[0mphrase\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m                     \u001b[0mjpype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBoolean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                     jpype.java.lang.Boolean(stem)).toArray()\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\jpype\\_jclass.py\u001b[0m in \u001b[0;36m_getClassFor\u001b[1;34m(javaClass)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0m_getClassFor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjavaClass\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m     \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjavaClass\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetName\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_CLASSES\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0, 1, 7],\n",
       " [3, 9, 19],\n",
       " [0, 5, 6],\n",
       " [5, 6, 9],\n",
       " [2, 4, 9],\n",
       " [0, 3, 4],\n",
       " [1, 2, 4],\n",
       " [2, 3, 5],\n",
       " [0, 2, 7],\n",
       " [0, 3, 13],\n",
       " [10, 14, 19],\n",
       " [2, 3, 8],\n",
       " [1, 2, 5],\n",
       " [1, 5, 7],\n",
       " [1, 9, 12],\n",
       " [2, 8, 10],\n",
       " [0, 1, 3],\n",
       " [3, 4, 7],\n",
       " [3, 8, 11],\n",
       " [7, 9, 11],\n",
       " [2, 3, 16],\n",
       " [1, 2, 7],\n",
       " [1, 4, 7],\n",
       " [0, 1, 5],\n",
       " [1, 2, 6],\n",
       " [0, 6, 8],\n",
       " [0, 2, 7],\n",
       " [0, 1, 4],\n",
       " [0, 4, 5],\n",
       " [2, 4, 5]]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def result_index(dfm):\n",
    "    textrank_index_list = []\n",
    "\n",
    "    for i in dfm:\n",
    "        textrank = TextRank(i)\n",
    "        textrank_index = textrank.summarize(3)\n",
    "        textrank_index_list.append(textrank_index)\n",
    "        \n",
    "    return textrank_index_list\n",
    "\n",
    "%time result_col = result(train['article_original'])\n",
    "result_col[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11min 9s\n"
     ]
    }
   ],
   "source": [
    "def result_sentence(dfm):\n",
    "\n",
    "    text_list = []\n",
    "    for i in dfm['article_original']:\n",
    "        textrank = TextRank(i)\n",
    "\n",
    "        textrank_list = []\n",
    "        for row in textrank.summarize_sentence(3):\n",
    "            textrank_list.append(row)\n",
    "        textrank_sentence = '\\n'.join(textrank_list)\n",
    "        text_list.append(textrank_sentence)\n",
    "    return text_list\n",
    "\n",
    "%time result_sentence = result_sentence(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id                                            summary\n",
      "0     500733466  ▲ 석문간척지 임차법인협의회가 한국농어촌공사 당진지사 앞에 공공비축벼 320t을 쌓...\n",
      "1     500742482  벌떼해장국의 주 메뉴는 뼈해장국과 감자탕이다.\\n또한 벌떼해장국의 추천 메뉴는 콩나...\n",
      "2     500742484  반면 면천면 휘발유 평균 가격은 1478원으로 가장 낮았으며, 경유는 정미면이 평균...\n",
      "3     504213810  어기구 국회의원이 천연가스의 안정적 수급을 위해 2020년 착공이 예정돼 있는 액화...\n",
      "4     505279620  그러나 지난해 정책자문위원회 소집횟수는 전체회의 1회에 그치고 있으며, 위원들의 의...\n",
      "...         ...                                                ...\n",
      "9982  745338220  지지부진한 인천 내항 재개발사업의 물꼬를 터 줄 것으로 기대했던 도시재생 혁신지구 ...\n",
      "9983  745367988  청와대는 30일 문재인 대통령의 ‘1호 공약’인 고위공직자범죄수사처(공수처) 설치법...\n",
      "9984  745368130  광주지역 광공업 생산 감소율이 14개월 만에 최고를 기록했다.\\n광주 감소율은 지난...\n",
      "9985  745368136  아름다운 가게 용봉점 헌책방이 개점 10년만에 문을 닫는 다.\\n헌책방은 매년 기증...\n",
      "9986  745368284  현대차그룹은 최근 한국렌터카사업조합연합회와 ‘미래 모빌리티 사업 협력을 위한 양해각...\n",
      "\n",
      "[9987 rows x 2 columns]\n",
      "             id              summary\n",
      "0     500733466  추출요약1\\n추출요약2\\n추출요약3\n",
      "1     500742482  추출요약1\\n추출요약2\\n추출요약3\n",
      "2     500742484  추출요약1\\n추출요약2\\n추출요약3\n",
      "3     504213810  추출요약1\\n추출요약2\\n추출요약3\n",
      "4     505279620  추출요약1\\n추출요약2\\n추출요약3\n",
      "...         ...                  ...\n",
      "9982  745338220  추출요약1\\n추출요약2\\n추출요약3\n",
      "9983  745367988  추출요약1\\n추출요약2\\n추출요약3\n",
      "9984  745368130  추출요약1\\n추출요약2\\n추출요약3\n",
      "9985  745368136  추출요약1\\n추출요약2\\n추출요약3\n",
      "9986  745368284  추출요약1\\n추출요약2\\n추출요약3\n",
      "\n",
      "[9987 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "submission = pd.read_csv('데이터/extractive_sample_submission_v2.csv')\n",
    "submission2 = pd.read_csv('데이터/extractive_sample_submission_v2.csv')\n",
    "submission['summary'] = result_sentence\n",
    "\n",
    "submission.to_csv('submission2.csv', index=False)\n",
    "print(pd.read_csv('submission2.csv'))\n",
    "print(submission2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['신 벌떼해장국이 손님들의 성원에 보답하고자 24시간 영업을 재개한다.', '또한 이와 함께 오는 12일부터 31일까지 특별 감사 이벤트를 실시할 예정이다.', '이 기간 동안 야간(저녁 11시~오전 7시)에 찾는 손님들을 위해 뼈해장국은 2000원, 감자탕은 5000원 할인된 가격으로 제공한다.', '남기순 대표는 “잊지 않고 꾸준히 찾아 주신 손님들의 감사에 보답하고자 24시 영업을 재개하고 작은 이벤트를 마련했다”고 말했다.', '벌떼해장국의 주 메뉴는 뼈해장국과 감자탕이다.', '돼지 목뼈만을 사용해 부드러운 살코기가 뼈에 가득 붙어 있다.', '또한 육수는 초벌로 삶은 뼈를 한 번 더 4시간 동안 푹 고아낸 것을 사용해 깊고 진한 맛이 특징이다.', '우릴 때는 무와 양파, 양파 껍질 및 대파 뿌리 등이 들어가 잡냄새가 없으며 이밖에도 국내산 마늘과 생강 등을 넣어 조미료 없이 감칠맛이 난다.', '여기에 우거지와 깻잎, 팽이버섯 등을 넣어 푸짐함을 더한다.', '또 대파와 청양고추를 넣어 매콤한 맛을 내면 한 그릇에도 든든한 뼈해장국이 완성된다.', '감자탕은 전골식으로 끓여가면서 먹을 수 있다.', '감자탕에는 생감자와 콩나물이 더해져 우러날수록 국물이 시원하다.', '한편 겨울철 특별메뉴로 굴김치해장국이 마련돼 있다.', '이미 입소문 난 메뉴로 뼈해장국 수준의 인기를 보인다고.', '굴김치해장국에는 직접 담근 묵은지를 사용해 국물 맛이 시원하다.', '여기에 통영에서 공수한 신선한 굴과 생콩나물이 들어간다.', '미리 조리해 놓는 방식이 아닌 주문 즉시 조리되기 때문에 콩나물의 아삭함이 살아있다.', '또한 벌떼해장국의 추천 메뉴는 콩나물황태해장국이다.', '황태 단가가 높음에도 벌떼해장국에서는 저렴한 가격으로 손님들에게 제공하고 있다.', '황태는 고소한 맛을 위해 들기름에 볶아 사용하며 역시 주문 즉시 만든다.', '지금은 단체 회식까지도 가능한 벌떼해장국이지만 처음 시작하던 15년 전에는 겨우 5평 남짓한 크기였다.', 'IMF 당시 남편 이복유 대표가 운영하던 대형부품납품업체가 어려워지며 문을 닫게 됐다.', '술을 좋아해 자주 가던 해장국집에서 마침 이 대표에게 가게를 운영해 볼 생각이 없느냐고 제안했다.', '하지만 갓 돌 지난 아들을 키우고 있었던 아내 남 대표는 그 당시 완강하게 음식점 운영을 반대했다.', '남편 이 대표는 식당 운영의 어려움으로 결국 ‘식당 주변 200m 아내 접근 금지’를 내걸고 식당 운영을 시작했다.', '하지만 쉽지 않았다.', '집 부엌에도 잘 안 가던 이 대표가 처음인 식당을 운영하기란 쉬운 일이 아니었다.', '아내 남 씨는 남편이 걱정돼 아들을 업고 식당을 찾았고 파 손질하고 김치 한 번 담다가 어느덧 15년의 세월이 흘렀다.', '“15년 동안 5번 식당 위치를 이전했을 정도로 다사다난했어요.', '그래도 손님들이 ‘아무리 도망가도 찾아오겠다’고 말씀하실 정도로 많은 사랑을 주세요.', '앞으로도 변함이 없이 맛있는 음식을 제공하는 벌떼해장국이 되겠습니다.”', '■메뉴 :뼈해장국 7000원, 뼈다귀감자탕 大3만 7000원, 中3만 2000원, 小2만 7000원, 콩나물황태해장국 6000원, 굴김치해장국 7000원, 해물뼈다귀전골 7만 5000원', '■위치 : 당진시 무수동 7길 123 (하늘채코오롱아파트 정문 앞) ■문의 : 041-355-3282', '■영업시간 : 일요일 야간 휴무']\""
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['article_original'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'▲ 석문간척지 임차법인협의회가 한국농어촌공사 당진지사 앞에 공공비축벼 320t을 쌓아두고 시위를 벌이고 있다.\\n석문간척지 임차법인협의회(이하 간척지협의회)가 농림축산식품부의 부당한 간척지 임대료 책정에 반발하며 지난달 30일 한국농어촌공사 당진지사 앞에 공공비축벼 320t을 쌓고 시위를 벌였다.\\n게다가 임차법인들의 계약기간이 올해 만료되기 때문에 임대료를 인하해도 지난 2년 동안의 손실 보상은 받을 수 없는 상황이다.'"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['summary'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500733466</td>\n",
       "      <td>추출요약1\\n추출요약2\\n추출요약3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500742482</td>\n",
       "      <td>추출요약1\\n추출요약2\\n추출요약3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500742484</td>\n",
       "      <td>추출요약1\\n추출요약2\\n추출요약3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>504213810</td>\n",
       "      <td>추출요약1\\n추출요약2\\n추출요약3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>505279620</td>\n",
       "      <td>추출요약1\\n추출요약2\\n추출요약3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>745338220</td>\n",
       "      <td>추출요약1\\n추출요약2\\n추출요약3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>745367988</td>\n",
       "      <td>추출요약1\\n추출요약2\\n추출요약3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>745368130</td>\n",
       "      <td>추출요약1\\n추출요약2\\n추출요약3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>745368136</td>\n",
       "      <td>추출요약1\\n추출요약2\\n추출요약3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>745368284</td>\n",
       "      <td>추출요약1\\n추출요약2\\n추출요약3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9987 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id              summary\n",
       "0     500733466  추출요약1\\n추출요약2\\n추출요약3\n",
       "1     500742482  추출요약1\\n추출요약2\\n추출요약3\n",
       "2     500742484  추출요약1\\n추출요약2\\n추출요약3\n",
       "3     504213810  추출요약1\\n추출요약2\\n추출요약3\n",
       "4     505279620  추출요약1\\n추출요약2\\n추출요약3\n",
       "...         ...                  ...\n",
       "9982  745338220  추출요약1\\n추출요약2\\n추출요약3\n",
       "9983  745367988  추출요약1\\n추출요약2\\n추출요약3\n",
       "9984  745368130  추출요약1\\n추출요약2\\n추출요약3\n",
       "9985  745368136  추출요약1\\n추출요약2\\n추출요약3\n",
       "9986  745368284  추출요약1\\n추출요약2\\n추출요약3\n",
       "\n",
       "[9987 rows x 2 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True    9987\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(submission['id'] == submission2['id']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
